{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aGxGrzUsrRz",
        "outputId": "9033fa23-9c71-44e5-db26-b37a3097a71b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6b5GJJzKBcyN",
        "outputId": "f7b89bb0-1b23-49da-ce94-83d503cf6a70"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wi-wf_dJBofF"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers.pooling import AveragePooling2D\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.resnet import ResNet50\n",
        "from imutils import paths\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import pickle\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lygwwOf372kO"
      },
      "outputs": [],
      "source": [
        "dataset='/content/drive/MyDrive/data'\n",
        "LABELS = set([\"Healthy Wheat\", \"Leaf Rust\", \"powdery mildew\",\"Wheat Loose Smut\" , \"Tan Spot\" , \"Crown and Root Rot\"])\n",
        "imagePaths = list(paths.list_images(dataset))\n",
        "data = []\n",
        "labels = []\n",
        "# loop over the image paths\n",
        "for imagePath in imagePaths:\n",
        " # extract the class label from the filename\n",
        " label = imagePath.split(os.path.sep)[-2]\n",
        "# if the label of the current image is not part of the labels\n",
        " # are interested in, then ignore the image\n",
        " if label not in LABELS:\n",
        "    continue\n",
        "# load the image, convert it to RGB channel ordering, and resize\n",
        " # it to be a fixed 224x224 pixels, ignoring aspect ratio\n",
        " image = cv2.imread(imagePath)\n",
        " image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        " image = cv2.resize(image, (224, 224))\n",
        "# update the data and labels lists, respectively\n",
        " data.append(image)\n",
        " labels.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tgHiglbhKgPI"
      },
      "outputs": [],
      "source": [
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "\n",
        "data = shuffle(data)\n",
        "labels = shuffle(labels)\n",
        "\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
        " test_size=0.2, stratify=labels, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgUfaha98iYp",
        "outputId": "0fbcb400-e8c4-4bc1-dd28-059734401400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4902, 224, 224, 3)\n",
            "(4902, 6)\n"
          ]
        }
      ],
      "source": [
        "print(data.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "S2IfVJiXZY7m"
      },
      "outputs": [],
      "source": [
        "# initialize the training data augmentation object\n",
        "trainAug = ImageDataGenerator(\n",
        " rotation_range=30,\n",
        " zoom_range=0.15,\n",
        " width_shift_range=0.2,\n",
        " height_shift_range=0.2,\n",
        " shear_range=0.15,\n",
        " horizontal_flip=True,\n",
        " fill_mode=\"nearest\")\n",
        "# initialize the validation/testing data augmentation object (which\n",
        "# we'll be adding mean subtraction to)\n",
        "valAug = ImageDataGenerator()\n",
        "# define the ImageNet mean subtraction (in RGB order) and set the\n",
        "# the mean subtraction value for each of the data augmentation\n",
        "# objects\n",
        "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
        "trainAug.mean = mean\n",
        "valAug.mean = mean"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainX.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAOd87vZNZ_G",
        "outputId": "a70f0206-8bba-44d2-f94c-212e0bfde285"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3921, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = trainX.reshape(3921, 150528)\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm=SMOTE(random_state=42)\n",
        "x_smote, y_smote=sm.fit_resample(X_train,trainY)\n",
        "print(x_smote.shape)\n",
        "print(y_smote.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow5hr7_dN4C4",
        "outputId": "7d36f57b-b761-4d0f-b40b-46f7dfd80879"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6138, 150528)\n",
            "(6138, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smote_x=x_smote.reshape(6138,224, 224, 3)"
      ],
      "metadata": {
        "id": "o8UyNav2OC_b"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.resnet import ResNet50, preprocess_input\n",
        "pretrained_model= ResNet50(include_top=False,\n",
        "                   input_shape=(224,224,3),\n",
        "                   pooling='avg',classes=6,\n",
        "                   weights='imagenet')\n",
        "for layer in pretrained_model.layers:\n",
        "        layer.trainable=False"
      ],
      "metadata": {
        "id": "RfEc9ktlOI0G"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUfx6DVyOLoH",
        "outputId": "475a095d-04d3-459b-dac6-d561302ead15"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 0\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from tensorflow.keras import layers,Dense,Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "resnet_model = Sequential()\n",
        "resnet_model.add(pretrained_model)\n",
        "resnet_model.add(Flatten())\n",
        "resnet_model.add(Dense(512, activation='relu'))\n",
        "resnet_model.add(Dense(6, activation='softmax'))\n",
        "resnet_model.summary()\n",
        "resnet_model.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO0FEyqcOOyZ",
        "outputId": "a5c1b4e9-dd3e-4396-9465-338092ebd9e0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2048)              23587712  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1049088   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 3078      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,639,878\n",
            "Trainable params: 1,052,166\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = resnet_model.fit(trainAug.flow(smote_x, y_smote, batch_size=64), validation_data = valAug.flow(testX, testY), steps_per_epoch = 62, epochs=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5mspg770ORz4",
        "outputId": "2e4ecd32-a182-473e-80a6-d5f8af0736c7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "62/62 [==============================] - 64s 794ms/step - loss: 1.9949 - accuracy: 0.2673 - val_loss: 1.7748 - val_accuracy: 0.2039\n",
            "Epoch 2/60\n",
            "62/62 [==============================] - 46s 744ms/step - loss: 1.5926 - accuracy: 0.3160 - val_loss: 1.8100 - val_accuracy: 0.1949\n",
            "Epoch 3/60\n",
            "62/62 [==============================] - 46s 741ms/step - loss: 1.5439 - accuracy: 0.3571 - val_loss: 1.7943 - val_accuracy: 0.1990\n",
            "Epoch 4/60\n",
            "62/62 [==============================] - 46s 744ms/step - loss: 1.5029 - accuracy: 0.3669 - val_loss: 1.7963 - val_accuracy: 0.2088\n",
            "Epoch 5/60\n",
            "62/62 [==============================] - 46s 745ms/step - loss: 1.4855 - accuracy: 0.3902 - val_loss: 1.8117 - val_accuracy: 0.2162\n",
            "Epoch 6/60\n",
            "62/62 [==============================] - 46s 745ms/step - loss: 1.4605 - accuracy: 0.3964 - val_loss: 1.8370 - val_accuracy: 0.2072\n",
            "Epoch 7/60\n",
            "62/62 [==============================] - 47s 749ms/step - loss: 1.4176 - accuracy: 0.4243 - val_loss: 1.8704 - val_accuracy: 0.2137\n",
            "Epoch 8/60\n",
            "62/62 [==============================] - 46s 744ms/step - loss: 1.4140 - accuracy: 0.4151 - val_loss: 1.8386 - val_accuracy: 0.1843\n",
            "Epoch 9/60\n",
            "62/62 [==============================] - 46s 747ms/step - loss: 1.3982 - accuracy: 0.4273 - val_loss: 1.8403 - val_accuracy: 0.2170\n",
            "Epoch 10/60\n",
            "62/62 [==============================] - 46s 749ms/step - loss: 1.3668 - accuracy: 0.4402 - val_loss: 1.8690 - val_accuracy: 0.2202\n",
            "Epoch 11/60\n",
            "62/62 [==============================] - 46s 749ms/step - loss: 1.3538 - accuracy: 0.4490 - val_loss: 1.9075 - val_accuracy: 0.1949\n",
            "Epoch 12/60\n",
            "62/62 [==============================] - 46s 745ms/step - loss: 1.3291 - accuracy: 0.4614 - val_loss: 1.9075 - val_accuracy: 0.2210\n",
            "Epoch 13/60\n",
            "62/62 [==============================] - 46s 749ms/step - loss: 1.3040 - accuracy: 0.4712 - val_loss: 1.9421 - val_accuracy: 0.2316\n",
            "Epoch 14/60\n",
            "62/62 [==============================] - 46s 747ms/step - loss: 1.3004 - accuracy: 0.4619 - val_loss: 1.9169 - val_accuracy: 0.2121\n",
            "Epoch 15/60\n",
            "62/62 [==============================] - 46s 746ms/step - loss: 1.2772 - accuracy: 0.4775 - val_loss: 1.9717 - val_accuracy: 0.1974\n",
            "Epoch 16/60\n",
            "62/62 [==============================] - 46s 744ms/step - loss: 1.2649 - accuracy: 0.4785 - val_loss: 1.9674 - val_accuracy: 0.2072\n",
            "Epoch 17/60\n",
            "62/62 [==============================] - 48s 766ms/step - loss: 1.2504 - accuracy: 0.4833 - val_loss: 2.0218 - val_accuracy: 0.2194\n",
            "Epoch 18/60\n",
            "62/62 [==============================] - 46s 745ms/step - loss: 1.2471 - accuracy: 0.4980 - val_loss: 2.0286 - val_accuracy: 0.2064\n",
            "Epoch 19/60\n",
            "62/62 [==============================] - 46s 747ms/step - loss: 1.2242 - accuracy: 0.5073 - val_loss: 2.0582 - val_accuracy: 0.1982\n",
            "Epoch 20/60\n",
            "62/62 [==============================] - 46s 746ms/step - loss: 1.2089 - accuracy: 0.5076 - val_loss: 2.0602 - val_accuracy: 0.2007\n",
            "Epoch 21/60\n",
            "62/62 [==============================] - 47s 755ms/step - loss: 1.1892 - accuracy: 0.5141 - val_loss: 2.1169 - val_accuracy: 0.2129\n",
            "Epoch 22/60\n",
            "62/62 [==============================] - 47s 755ms/step - loss: 1.1763 - accuracy: 0.5199 - val_loss: 2.1930 - val_accuracy: 0.2064\n",
            "Epoch 23/60\n",
            "62/62 [==============================] - 48s 773ms/step - loss: 1.1708 - accuracy: 0.5245 - val_loss: 2.1649 - val_accuracy: 0.2170\n",
            "Epoch 24/60\n",
            "62/62 [==============================] - 47s 756ms/step - loss: 1.1575 - accuracy: 0.5292 - val_loss: 2.1602 - val_accuracy: 0.1835\n",
            "Epoch 25/60\n",
            "62/62 [==============================] - 47s 759ms/step - loss: 1.1164 - accuracy: 0.5421 - val_loss: 2.1903 - val_accuracy: 0.1949\n",
            "Epoch 26/60\n",
            "62/62 [==============================] - 47s 752ms/step - loss: 1.1386 - accuracy: 0.5429 - val_loss: 2.2092 - val_accuracy: 0.2031\n",
            "Epoch 27/60\n",
            "62/62 [==============================] - 46s 748ms/step - loss: 1.1169 - accuracy: 0.5459 - val_loss: 2.1965 - val_accuracy: 0.2080\n",
            "Epoch 28/60\n",
            "62/62 [==============================] - 46s 747ms/step - loss: 1.1090 - accuracy: 0.5543 - val_loss: 2.2514 - val_accuracy: 0.1966\n",
            "Epoch 29/60\n",
            "62/62 [==============================] - 48s 768ms/step - loss: 1.0812 - accuracy: 0.5703 - val_loss: 2.3050 - val_accuracy: 0.1884\n",
            "Epoch 30/60\n",
            "62/62 [==============================] - 46s 748ms/step - loss: 1.0883 - accuracy: 0.5631 - val_loss: 2.3221 - val_accuracy: 0.1843\n",
            "Epoch 31/60\n",
            "62/62 [==============================] - 46s 743ms/step - loss: 1.0644 - accuracy: 0.5791 - val_loss: 2.3882 - val_accuracy: 0.2096\n",
            "Epoch 32/60\n",
            "62/62 [==============================] - 46s 742ms/step - loss: 1.0670 - accuracy: 0.5734 - val_loss: 2.3785 - val_accuracy: 0.1966\n",
            "Epoch 33/60\n",
            "62/62 [==============================] - 46s 740ms/step - loss: 1.0469 - accuracy: 0.5801 - val_loss: 2.4060 - val_accuracy: 0.2015\n",
            "Epoch 34/60\n",
            "62/62 [==============================] - 46s 744ms/step - loss: 1.0714 - accuracy: 0.5590 - val_loss: 2.3849 - val_accuracy: 0.2039\n",
            "Epoch 35/60\n",
            "62/62 [==============================] - 46s 746ms/step - loss: 1.0496 - accuracy: 0.5713 - val_loss: 2.3813 - val_accuracy: 0.2080\n",
            "Epoch 36/60\n",
            "62/62 [==============================] - 46s 743ms/step - loss: 1.0117 - accuracy: 0.5876 - val_loss: 2.4738 - val_accuracy: 0.1974\n",
            "Epoch 37/60\n",
            "62/62 [==============================] - 46s 741ms/step - loss: 0.9951 - accuracy: 0.6026 - val_loss: 2.4097 - val_accuracy: 0.2080\n",
            "Epoch 38/60\n",
            "62/62 [==============================] - 46s 741ms/step - loss: 1.0125 - accuracy: 0.5871 - val_loss: 2.4322 - val_accuracy: 0.2137\n",
            "Epoch 39/60\n",
            "62/62 [==============================] - 46s 739ms/step - loss: 0.9935 - accuracy: 0.5944 - val_loss: 2.4779 - val_accuracy: 0.1917\n",
            "Epoch 40/60\n",
            "62/62 [==============================] - 46s 744ms/step - loss: 1.0014 - accuracy: 0.5953 - val_loss: 2.5122 - val_accuracy: 0.2039\n",
            "Epoch 41/60\n",
            "62/62 [==============================] - 46s 743ms/step - loss: 0.9844 - accuracy: 0.6021 - val_loss: 2.5703 - val_accuracy: 0.1941\n",
            "Epoch 42/60\n",
            "62/62 [==============================] - 46s 738ms/step - loss: 0.9860 - accuracy: 0.5952 - val_loss: 2.5109 - val_accuracy: 0.1990\n",
            "Epoch 43/60\n",
            "62/62 [==============================] - 46s 745ms/step - loss: 0.9776 - accuracy: 0.6118 - val_loss: 2.5384 - val_accuracy: 0.1892\n",
            "Epoch 44/60\n",
            "62/62 [==============================] - 47s 765ms/step - loss: 0.9483 - accuracy: 0.6153 - val_loss: 2.5774 - val_accuracy: 0.1982\n",
            "Epoch 45/60\n",
            "62/62 [==============================] - 46s 747ms/step - loss: 0.9336 - accuracy: 0.6153 - val_loss: 2.6290 - val_accuracy: 0.2031\n",
            "Epoch 46/60\n",
            "17/62 [=======>......................] - ETA: 30s - loss: 0.9378 - accuracy: 0.6100"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1c4446167e86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainAug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmote_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_smote\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalAug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m62\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = resnet_model.predict(testX, batch_size=64)\n",
        "print(classification_report(testY.argmax(axis=1),\n",
        "                            predictions.argmax(axis=1), target_names=lb.classes_))"
      ],
      "metadata": {
        "id": "itoMm32UPGld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 200\n",
        "plt.plot(np.arange(0, N), history.history['accuracy'], label=\"Training Accuracy\")\n",
        "plt.plot(np.arange(0, N), history.history['val_accuracy'], label=\"Test Accuracy\")\n",
        "plt.title('resnet50 Model Train vs Test Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "plt.savefig(r\"/content/Accuracy_Plot.png\")\n",
        "plt.plot(history.history['loss'], label=\"Training Loss\")\n",
        "plt.plot(history.history['val_loss'], label=\"Test Loss\")\n",
        "plt.title('resnet50 Model Train vs Test Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()\n",
        "plt.savefig(r\"/content/Loss_Plot.png\")"
      ],
      "metadata": {
        "id": "rAzTFaHEPLjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwbbBrF85fL1"
      },
      "outputs": [],
      "source": [
        "#Save the Model and label file to Disk\n",
        "resnet_model.save(\"/content/activity_model.h5\")\n",
        "f = open(\"label\", \"wb\")\n",
        "f.write(pickle.dumps(lb))\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "model_path = \"/content/activity_model.h5\"\n",
        "input = \"/content/input_image.jpg\"\n",
        "label = \"/content/label\"\n",
        "# load the trained model and label binarizer from disk\n",
        "moodel = load_model(model_path)\n",
        "lb = pickle.loads(open(\"label\", \"rb\").read())\n",
        "# initialize the image mean for mean subtraction along with the\n",
        "# predictions queue\n",
        "mean = np.array([123.68, 116.779, 103.939][::1], dtype=\"float32\")\n",
        "Q = deque(maxlen=128)\n",
        "vs = cv2.VideoCapture(input)\n",
        "(W, H) = (None, None)\n",
        "while True:\n",
        "   (grabbed, frame) = vs.read()\n",
        "   if not grabbed:\n",
        "      break\n",
        "   if W is None or H is None:\n",
        "      (H, W) = frame.shape[:2]\n",
        "   output = frame.copy()\n",
        "   frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "   frame = cv2.resize(frame, (224, 224)).astype(\"float32\")\n",
        "   frame -= mean\n",
        "   preds = moodel.predict(np.expand_dims(frame, axis=0))[0]\n",
        "   Q.append(preds)\n",
        "   results = np.array(Q).mean(axis=0)\n",
        "   i = np.argmax(results)\n",
        "   label = lb.classes_[i]\n",
        "   text = \"PREDICTION: {}\".format(label.upper())\n",
        "   cv2.putText(output, text, (4, 4), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "      0.25, (200,255,155), 2)\n",
        "# show the output image\n",
        "   image=cv2.resize(output,None,fx=0.25,fy=0.25,interpolation=cv2.INTER_AREA)\n",
        "   plt.imshow(image)\n",
        "   plt.show()\n",
        "   for i in range(0,7):\n",
        "     print(lb.classes_[i])\n",
        "     print(results[i]*100)\n",
        "   #print(LABELS)\n",
        "   #print(results)\n",
        "   print(text)\n",
        "   key = cv2.waitKey(10) & 0xFF\n",
        " \n",
        "   # if the `q` key was pressed, break from the loop\n",
        "   if key == ord(\"q\"):\n",
        "     break\n",
        "vs.release()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "pITbasB2LkXX",
        "outputId": "293dc9e6-084e-4ca8-f9e3-29c0e995c969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO29aaxl13UmtvaZ7vjm9+rVq4EsDkVSFMVJlERFalsmJUtWlBYSGE67G4ESCNAfJ3AjDlpSAgTdjQSw/7TbQBIDREttBXEsudt2pJbVtmWasixZE2lq4MxiseZ69eY7n3nnx71117cWWawnFesW23d/QKH2fXvfffbZZ+971tprrW8Zay05ODj8/Yd3owfg4OAwGbjN7uAwJXCb3cFhSuA2u4PDlMBtdgeHKYHb7A4OU4Jr2uzGmI8YY140xpwwxnzmzRqUg4PDmw/zs9rZjTE+Eb1ERB8ionNE9AMi+lVr7XNv3vAcHBzeLATX8N13E9EJa+1JIiJjzBeJ6ONEdMXNPjPftCtri0REVGlIoQJ/dIwxV7wo/jbpZmUJH1SdB5/tlZsJdONSfG5UeMxvMESBPJM/pkHIX9Q/s9hlr5/DtXzZ0OPHZtU4iiwbl8uiGJerUSjadbtd7s6Xz8L4fL0SbtRT1/JhxPqlgePCWcytnNMcHlogq6geRONyWnL/5WvGy599Nas5zEcF+jOeXPpFwJ+TLBF1nuV59Eo5yNDwteW6kpPlwfitmoMSPhfwdy+Qz8yDa3menIMsT4mIqLW+S/293uuuzmvZ7IeJ6Cx8PkdE73mjL6ysLdK//PxvEBHR8fc2RF2W8w2HwZW1iyzlujCSkzbowXSrO6tV+P7TgttF/pV37d+8NBCfH761CmPc327fWM/F5wMHeWBFKfvwPR7Xd3+4Oy7XwqZoZ+uL43KudmBrY3Nc7uzujMt3HTkk2n3rO98alxtzdVEXzM2My3FYGZer6p5nYcGVWSHqcpjXNmyDnaQn2m2l/PlAV/Z/38qxcfnsIOYxzcr5CGZ5Lc3ZWNRtXVgfl29bPjoue7Mrol17YWlcPnHhVVE3W+6Ny7WO/CE4FPGaiOE+IyMXYHXA68Amcl31S/68U/I8NpfXZB8BP6daTT6z9a3hVvy9T/0fdCVc9wM6Y8ynjDFPGmOebO92r/4FBweH64JrebOfJ6Kj8PnI6G8C1trHiOgxIqJjdx21aT78hXvqJ3uiXQq/aL6XibpDC7PczrAo1i2rop2Xb43L2exRUbd7ia8XFfzr37RSRK7P8JS026mo+/5z/Ou8PMMiVqBE2Bh+xQeFvJcLe/Pj8mxT/nIX6cVx2aQstSTqbWh9vu9TO5uibqYxx32E/MY72doR7fogZlZS+UYNE/4cBjw/oRJ9PZAqQk/OQQHiLkifZEvZDoWziiefxe4uSzelx/P93uP3inbPXjo1Ll/M5TMbgHRTXWDpJqhIEfnVAa+PQSClFOpwnzaV/echv2FRpO9utES72VmWHAalvM+IeE2HOY/3yMKCaPfyqUvc/5KUaneS4ZrOlZqBuJY3+w+I6Lgx5hZjTERE/4iIvnIN/Tk4OFxH/Mxvdmttboz574noz4nIJ6LPW2uffdNG5uDg8KbiWsR4stZ+jYi+9iaNxcHB4Trimjb7T4vSWuqPdPPNttSL4pRPObuDjqjzS9aLzm+yHjd78CbR7uyF7XF58a6bRd3JS/1xuZ6zTj2TSB0sXOKT6H4sT00HA56urW3uby6MRLtqxrrsuVzqqDOHWHd7/kdnRN3dy/y9Kuhe/UzqYXGLDzp7nb6oiwI+PTc5j7+zJ0+RI9D7F+dWRV0Jyl0JcxU15AmwxfMINcZAWQvHf1cmQB9MjDPNWVG3d5H13nL5IPehVOq7mnyy/q1T8tgoAMNf0eb+vKUDol3h8zi8XM5p3OXPeU+uiRk4gV+ogJUgle0ifix0sS8tBrcd4rV66SU+OygH8rwHrVSttjwT8Ivhfb6Rjci5yzo4TAncZndwmBJMVownS71iKC6lnhJNSxYzc+UFtQMmsKQL4lG/LdqZkEXEnUSa9owPHnoZ99fuSHEoarBIHis3uT6oF7Pg1TanZFa0/qwdlOrEq+fZD2nOSnWFclYhOsRi5eU5G48/4fucXZLOId0W38/hqDYut7tSjL/9KI+rvyfnajOG+1zm/v1Me4XBZ+XVVgGHmwpMSEWZ70zMz2VJOcs8170wLlePscp25tVXRLub59nJ6GaqibqLUE5A7Sh70udjZYa/1+8q81qVTWDbaq4G4OQVdMBBqC5VkhK88PJQrn0T8fpJC67rFlJfWW+zChsVco80qsN1672B97t7szs4TAncZndwmBK4ze7gMCWYqM5uiSgfKRV5KC+Nukqi9L+EWKcpLNf1lN7VN6CX+8q0ByaY0IDOZGW7xgzrWjvnzom6OpjpvArreFkmTSSz86zn9mKpK9s9dm+t1aTulho2bYHHKvVJ9h8PWHcrFqSOGtb582qTzXx1T5oHL7R4HK2tdVFHTQh+AZfYWiD72IHIuZpaSVUIbJrz+XvWl/dc+DzeIJVnE3sQMFLJ+Fp7Sl89Bu7UyzXpQm2XwaxY8Nq5eFY+23yFTXGNijwH2WvyGUn77POizsAzKxJ+TmFdTshul89B+lY+zxQ+r97MLtSJkXOVwPr2E2m+Wxyt28Bc+f3t3uwODlMCt9kdHKYEk/egG4m8cagixcDMUKgosmUQsdB7bLcjxXhvmU03g1yKhCgq+WCiIy32ZPy9MJN91FH6B9E9V+QSFuwfeXtb1DUD7rNQ1+4CdUGv5HaJUjViIJfY7EpT0FrA5rsSTG9RKD26Nlv8PU+ZGE3K97ZQZTE1iqQYjwweluQcZBmLmUXO7Qp1L0fmWGRub2yIum7GnmtByf3ZUIrqZyHyT/MTzNXYLBeA2e/Mrpw3v8FrZ35Rxv4/e+Lpcbk+MyPqMojiq4HXY3cgvfD6VV5zjcVFUdeCNe0bbpcoD86iYDVShctTb2s4B4Va9wj3ZndwmBK4ze7gMCWYqBg/PI4finEmV4QJQFpWUwH4SA6BwRj9lgruABEoVl54lRB+19osEvpKVA8gSKGqTochloHAIY8GqRxHvwNiZS7vZQYiIjqKrCEHEXcAIluixpgCr11ek320waMrmueT3c2T0ussBi/CZiSXQZ6Dpxk8pkFPkmiEEHaRKV61DgSM+MClVoSKLKTBqsYrm1uiLoXT+HSPvSWDJUnqcB682g4dOSL7T8FLscLif39WWjEqB5j0o7t3UdTdVPDz7VQlnVoMquQsrIl2S6oJfcNjXiplQNFcla9d5HytoCpP7V/12KMwLeWaWN8eWmjw2Wm4N7uDw5TAbXYHhymB2+wODlOCyZrejKXByCsoUeQGacI6yGwgTSsXTp3muoPsEXVmU5ItrgL3954iHiyBXKEDZpFlFVlk+8CnnkkvpShiXasKv5OJMhV2gSByQZFi+pY/Vw8oE0zMhIIpRLoVqXxMJRBP3LQoo+oI6JgbAzRdSZ3aB9OhqUiTmk34e+mA76XM5Vyl+K5Q9N85EEDUZ4EQROmUmxDRuLO3K+qsD558Puv9laYc76k91mWjROrURxq80KKY72VuWZJXIEFF//kXRZ2J+PkeXJXnBekWj7kLkZsmlnN1MGPyjeMzkizk3DafVQQ+91FXZlUyvCbaiTQ7B6PnVFwnwkkHB4f/hOA2u4PDlGDiprdixEGX5FJEzkHsTpQT0AB51uY46ME0pYg8gICRRKXHSTGxDmQvSZXJKIbMIxXtpgTiOnoqlUaK8ahAdJXomwTcNq1IXaYDEm4BYmCjLr22qhEHuNQSlQopA7E75f6NIsDwYPxesyLqBmDWeekkk20sHZCeZfUVFmk310+LuhXwSCtFAig535c22MNwpyPJSKLl5XF54xwH65iDMidABumaLmxcEHVHDt0yLvtArncglfP23Zc5a1klleJzo873kvUk2Uka85irKasaB8Il0e5uGMeZLal+9iBbUQN4A8/tyXaoKgWaba4/moPyyuwV7s3u4DAlcJvdwWFK4Da7g8OUYMLkFZbKkWmgKKUuW4Bu6yu9IwPSiC58z8xIt8PWgM0ReU26Q6JlyAIBRj9WLrFV7n+hIvsw4IJrgGzDU+Ptwb0EvjQT9SEibmDU4QTolB4QLTQPLItm3Q7raws6bTXMAXUh9bIiTMjg7KClzhz6MORdIJ9cnJUkihZ8hsNQ8sFjWmIZiSXfLzGY4pAMg4jo8E1MMrnT5rqgVOcxCevspTbpQgRfBHM6vyVz37VeOTEuH1yT5rVsj89BPOX+XCt4Cy1GbFJ71/3vEu1+8ONvj8sDIM8kItoFfvgHgXyjo4hMB5CjMNEq+8hlu7DXYHozxnzeGLNhjHkG/rZojPm6Mebl0f8Lb9SHg4PDjcd+xPjfI6KPqL99hoget9YeJ6LHR58dHBzewriqGG+t/aYx5pj688eJ6AOj8heI6BtE9Omr9WWMIX8UfWZV1A4VSHAgqyLw8OqDh1tFifExpDk2OrUu8INh97cdPy7apSDe+YXiSwMVogTR3SqRKgGvvDiUlTHMeK68zsKYx5wnwDOeShF8fobTPrfOnxJ1dy2zyccCT1lPeRTmICIWisM/g3ElHn+vF8uoNwPvClsqj0UQmS2oCWUp7yWqstkvVs+s0mST1yJyyynOv6xEM6U0x1bhc3uHTWpHKnLtrNbY864igxgp8uC5dyWhxFLEz+KDH/jwuPyVP/0T0c6s8IOPQ3kBD8zESJ2YKC+8voE1rLwed0fP8MrUFT/7Ad2qtfZyHOA6Ea2+UWMHB4cbj2s+jbfWWiK6oiXfGPMpY8yTxpgnB63+lZo5ODhcZ/ysp/GXjDFr1tqLxpg1Itq4UkNr7WNE9BgR0eoda5ZG/Gml1cemLO7GalSVCv8mYXbTSAWxJHDS7SmPsQxOfQ2I1jtdmYKpCaKk9ozLYhCjIOgmU791eFjcMlLkHMBxsdeRIuEs6C8JXKtQ5Bg+9LnYlCmTliDopLvDjyVV2WorMAeFoixGC8Vqnc9e36FUnpNnTo7L1sr5tgboo+ExecoKU4Lc6kfSk68DHov+Mt9XK5PqRB+IPg5VpBi/eYmDi/pAqFGpyfk4usgWjzMbklo7bLJVZjGQ3oz/1SO/Oi7/6ff+w7jc7kuq6rtu+9C4/EwiX3pHgVNwC7KzdgfSy7QIea66ah57zeF6LP0r53H9Wd/sXyGiT4zKnyCiL/+M/Tg4OEwI+zG9/QERfYeI7jTGnDPGfJKIfpOIPmSMeZmIPjj67ODg8BbGfk7jf/UKVY++yWNxcHC4jpioB50host+Vn4hdSbrsV6aKF28UmG9tN8GHVup/Tn04UfSo6sKHOdZm81raV/qONU6k/9lahw5pPxFyvfc6rMDOH9IlKlmjk1jQSp1fQ9059JAZF4sdbcLF9nb6+ix20VdNuA52NpkYgU89yAi8iFariA5V9mAr/3gf/bAuPzUi0+LdgWQVs4qDnz0iCQw7WmNMoAIxMbcnKjrg7kwqvHZwfmWjDzzgRi0oRZFAaayHujDbRUVeazJpri0cljU1av8zD527AFR9+y5l8blZ17lyLn5phrHPJ8l7F2U0X1rMCtxj/V5q4g+SjirGagzqfnDwzH7ypMR4XzjHRymBG6zOzhMCSYuxkcj05mxUow3wM2ddqWYk6ywCDQormx6C8CclCr+OB8kIh9E65lcmnuqYP6KlXhewucCAiK0uaP0WJTqtKRp72AT0hi1pQnJX+J+DJBt5NuSxKBWsFmrquTiDMTAXeBHayl++RK48MJCzsHhGSapwLiKE+dPinYrC8yhVwtkHwRzYME0WSozZQ6vm9qsNGtZML2FIHbvbcuUWh6aFRXHfh9SKHWB5KJTkUt/DfIYzIBXHBHRXQduHZcr87Luz//j57hPj9ft3EGpXp2E2+5rvj7w/JwBk672zExxHpVnS7M+VEN878rvb/dmd3CYErjN7uAwJXCb3cFhSjBRnb0gop2RWSpIpUKy02e9K9xTuizmSgb30FwprCXo/YGvCA6AsMICo2VgJEHFAOKGslSRYoIebXPWgSvK9bdMWW9OUpV2t80c4VlLcX9D+mIPzHemI/X+Ww+xPqiJMxJwscTU131F8Fm3rHs+fPc7RZ1vuO1fP/0Ej0+RZ8aGn9leV/bfWGBzlYdzn8mzmhBINLymNBth/j8Ck2tdpTNLwQW57EpX1ASutwvkD3O5dEHegFu7T+nb77v7oXH5//rKvxF1lyyfp3hg9kyXJOFIy0M2UXVeBdFtOxDtGNYkWUiRsBtvoyLnKt8brjNbON54B4eph9vsDg5TgsmmfyKiZOQtZBIpRtkei2ndgRR9m8ts4rGHmTN896JMQ2zAw61U6ZATEAmRE81UlbgPpBqlIthIwaNppspmosiT01gM+F4GygS4B2bFUIm0DRCTLXiWLVVkSqODICJnuYo2gznY7jBZQ9iQZq2PPvrIuNzuSZ70QcHqxeYGpy8OZyVhQgbPcGtbmksPwvV8iOpSmbLIF3Mn1bIMzGYzMZsK44FcO3MNnp9Ci/FA4BFnXHdmXUa2rd709nH53W9/UNS9+PKPx+XnXv2xqPPQpgvbqbm4Itr1IEqt7qu12ef1Eseg1igv0BJSX2sVczAiZ7kmDjoHB4e/H3Cb3cFhSjDZ9E9kqRidiHqKb6wNImFyQGbYjI5wBswunG4vFZpHmT9b5V1XwKl1DkQLRnkzdQdIWSz7QHK8FETMIJSECa0d9vCKZ6QodnaPCSVum5ei3gB54kANuXn1VtGuHrDYujmQlMgliHEdUBP0KXh7l8extXtR1G12mXihBK8zsvJeem0QJRXBRoDEEzhv6rQYnd8C1X8OKpC3y0EsVgWBHAJOvjyVlpzcsuhucD4U7959D753XG5nUhX4/pN/w+MopQWlClYTb5HHUS5IwuUcCCsqHdl/1ue11FxhhreLKktxFYg5OpuSL8a/vPZdFlcHBwe32R0cpgRuszs4TAkmnLK5pGDk5ZZoM0uDzWvzD79P1J3rs45zC3xtVvGpo3nNDxWJIqQWShNIazyrCCpAn/eUWctA/wZ06lKlIUaShKIhCRn2Yr6XLJBeVjmY+tCCsnJwTbQb7PC9ZGoOSuBU78K5Qr8ux/jUj78/Lt91yzFRl0A0noVzC99Ik1EE7wrlXEcmBxubIKOU4zBw7lJRJswUSCmymOc0UpzvNXgWe+osKIHoSiTKeP+D0mtwcZb17W8//T1RlxWgb8dy/DmQVBRgbmwps9lgwPNRU9zzYicA+UTp6zTb/L10V55N1KLROruyyu7e7A4O0wK32R0cpgQTFuOJ8hFJQKK8oJZW2Qy13pfeWAvQ9DYwc20pbjYKWIYZKE72ZJe9lBpAtJDE0pRiwHTh6zxU8NNYgGiaKHMPmuVMV5rlekBOcFF5QTWBMP+OJRbdi1K2a3fZtJcpU5YH8vS9IKp++/RT8loQdBIr7vxOm8XWPvQXqcy4psv3Xc/le6O3zX0uzHPwUqSmNMZMtspzkoC/fgD88jVfisiYYquryDGyhMXsW1dvG5cfekBmWf2755hf70cnnxF1B3xQDUIV9AS5BRozLMZnnlRTQ/Dsy9V8eyu89lPYkYlKleWHrL684yHJ97oyUhfP/N9/R1eCe7M7OEwJ3GZ3cJgSuM3u4DAlmCzhpDVUSYa6TKxyj+0UrMd4m9IFtLoLqYfh9ym2Upcta6w/aULLuMf65QyQAsRK7y+g/0gx/iH/pEEeeuWiiMSAiXIjtR6kn1a84Nk23/exu+7j/vZkVFq/y59tVZ4JGEjFPA/nIO3npYumDyl/9zryjKQLpk5MTT1TlTr7zgWOHDsQSD26D4QbSJ6ZNSQxpRdBNGIh56OAM40g4Ha1iuzDB+NVqdI514AT/4Mf/OC4/Pypl0W7v/0x6+zdgZyPJoy5MScJJQZw5lOJ+Fkk6vwhvsAuyavz0pW2DenEG01+Lss33SHaBWvsStvvyXX7tc//WyIiau3t0pWwn/RPR40xTxhjnjPGPGuM+fXR3xeNMV83xrw8+n/han05ODjcOOxHjM+J6DestXcT0cNE9GvGmLuJ6DNE9Li19jgRPT767ODg8BbFfnK9XSSii6NyxxjzPBEdJqKPE9EHRs2+QETfIKJPv1FfhixVRmmVjeJOm0tZ/Dz7wnOi7r94gD3qdlospuzF0uQVgTnPelKMz0CssiDGG+XJ58HnQnGQFyCeC07zSJI6VCH18CBWnGtAXFAN5Pc8EKfr4IHWUumOUDXQUXvVGpt/LkKaq0SZ+fbAy69aSHNSD1UPUFdCNR858N2lmZzHAFI5bQPP+0xTegMWEMGmaAPpwAL3gZGEM3WpuqQQNZYpUpRffPSj3A487b57Qq6xfpXregOpll3qsag+G8ktY7vgVQlLurO5JdqFwKGXLiuPSOCkWz3InP3bKuqy0+b18cJ3vy3q2runiIioVNx6iJ/qgM4Yc4yIHiCi7xHR6uiHgIhonYhWr/A1BweHtwD2vdmNMU0i+iMi+qfWWnGCYYevOXuF733KGPOkMebJQXvwek0cHBwmgH1tdmNMSMON/vvW2j8e/fmSMWZtVL9GRBuv911r7WPW2oestQ/VZmuv18TBwWECuKrOboY2ps8R0fPW2n8FVV8hok8Q0W+O/v/y1fqyxlI8SjtrVZjU+g/YRfHu2+4Rdeje+iKQKCZ1KUz4YMKIB1KfN5jrDVw7rXKJTSFtcuBL3Q2DtwpgwolUmuAaRC4lA+mOay3fi2fktZeBcaUPrqix0kMxlXGjlD+gLYj6upSwAFaovHW7QHLYzORvfscCcSecrZSK7WYA/PgL84dEXc3yecSFDWa+mTl2ULTDnHlE8kygBbnqTMlj9D1p5uuAme+uO+8WdY1FJuf81rNPjssnu5Kdp95kY5I18rkP4FksqHx0AZzxtLb5fdcycq5uAnPbXl+uzcNv4zFvE899oUy6p576wbhczaTL7eV8eq8rXo/HenW8j4j+GyL6iTHmh6O//c803OR/aIz5JBGdJqJf2UdfDg4ONwj7OY3/FmmOX8ajV/i7g4PDWwwT542PR6JroH4/DAT06+iqp19hb6dWymJxUZOeVBl4FQ1i6TFmgHghBInWy6XgUwBhQK7EKA/EdUHPrWSnOnDKX9iQ6YWbIKqnfSm2rq2yiIupl3PlhVeiZ59SQwbgVbgF5qpIESwO8i5+EHUZrIoi5f4Hymsrz7hutibF2xBIHg4usYjvlXLJDSAtVayIJBNQIZrgNYfEi0REns99rqwdFnV/9bdMFvnS9tlxuadMVH6fxedAEUBkELFmKnJtNoDkdBM8IBurS6JdH0yuR49Lz7iyxtFszZjH9dJ3fiDaNfpsLh1YlS9gnGLrSu9l5xvv4DA1cJvdwWFKMNksrmVJncFQJJpRIvIciGaN1UVR9+IrkOYJuOWyQopiHgS75Oo0vgDxqwlcZxEpggAQgzIVVGHgBD4E77dU8Z41gCPNqJPjJoj45UB+bxb6zJCnTInqaAmwSofA1Eht8JLT1o/SQru+VHlS8BIrof/enjwBXmswh16s1KabDjFRxAqI+M+unxbtDh47Ni6f2tVBScCnPstrIk7kvdxz7zu4j/NnRV0r4Tnog/Ug25FeifUmWGgakuMOPSc3FV97tc4c/gbUmipJ78iVtSPjcmVe8hJmEOh04TvfHZdnB3JOy4LnY6BJVy6rQDq/FsC92R0cpgRuszs4TAncZndwmBJMlnCytGTHqWWlbtGECCdfRTXZJa5LexDJpfRQH3TnMpH6dtjkSLeguDKpJBIteIq8IgNyhShkU9C5c+dFu9kDTBrhBdK7zgMiwnqoUiDDkNt91ql9T/4mG/hsVfRgDpFpKZjs/FyaKQvgUM8zeX7iR6yzLs4xWWRNnQ+0E/Zw66oIxJkjbAL7yyeYh/2Od94r2r148kfjso2Vvglmv7l51tlvP35cNHvuhRfH5TPnz4m61OdxeWCuCnTOuTbrwJHykhvAMohVBGIDCCgrS5yjMGo0RbvZechH15PkLBce/zqPC4hJaqsyr0DnEp+ZtHZlH/7ouRunszs4OLjN7uAwJZgwB52lYGQaSlVqJc9nMXNDmXFqYIprvQrBEdoklYJJqpC/Y2WXzToJQfonI0V15C0IlRifQ9BGBqma1jvSS64GwRdNX4rPMeTnOaQ8AP0+j7EA4gLjq4AfEONFSmUi6hfcB6Y8DnzFo0+sKhVWirTLQO6xsc4BI9GcNEmVCfd/30MfEHXrl/g5HTnKZqcf/923RLvaDAS4WPncl5bYrHXHHbeMy+fPvSranTnz0rjcVabULpgpEwhUSVTwTxc49CptGSRTM9x2T6emNqBKznEfNx+UIjhm33pJpZcyAxbduy0W1XuNhmg3SHg9Rj2leo1UWifGOzg4uM3u4DAtcJvdwWFKMFGd3ZYlpSOTkldIV9FtIORbSaXuFoD7aRVcOdvbkk+9CWYoW6roHzQ1wXmBUTp7iaY39VvoQ1sknExUtNb5nU1uV5GmtwD07UZFmmdwjJ4PxJeldnXluqSQdTmY9gqYY9/TZkSYA+UWvHOJdVbkcs/UOcuhQ0fHZZ1bL/BY73/qe98Zl2+6TZJXeEDE0Y5l/ysrfPaxu8Mc9a+cky63HSAX7fvyPpM269g5zGOvL11zkRO/jOUzK+CZeRVpLq032KTWnGdz40xFRr29+BTnYKsrN9gM1tXFLTapVeakW23Y4HOW1nlFLNkZzUHpdHYHh6mH2+wODlOCyUa9FSV1e0NxLzBSjLoInkOrSjTFePy5WRZ9tzbWRTOM0PKUCQKj2WIwnyDxARGRB30YZZKyEKnngeiVq2ttttgUd+SA5Ag3KffRVHztBrzfLIjqRqkCOaSNyjI5V0kVvOtgXKUijchTvtZCTXosbgMJQ3UWPA8D2cfWJeZGX6wcEHXf+v5fjMsFRGs1FMd+Ap6CSqOi2YNscn3+PEc+bidy7UTA79aMJLnE9vlnuX9UjZQ3YMVCJKSVkYqE5timNIdVwTPzrjsfGJd/8oI0D+6cYdXj8IJcV1UwwYYlkKyo1NT9nJAwL8sAACAASURBVDkFYxXx6V82xSniDYR7szs4TAncZndwmBJMnLxiZ3TqvjInvccSEKty5UFnE/5N6oEI6yuRqrML9Mi+DkDhPnI4fdbBNBa+V2qePBDrM/hepg5Ae0AVXKiT7oNA0uEp0gsCPjwDBBuF8hRM4Hu5oohOwXMwBQrqekOKtz7w6S2oebwEQSGYdqmmRMSbjx4bl188K4OBPLjvSo3FUd/I9wtqQAePHBF1py5yny24l3BJqgw5zFW8ITOwWiDzSELgF1SBUhQB8YSnePJADak35An5HXdzYM8LJ14Yl8+eOinazQQ8jsxIVaaEoJz5BVZdesrK08l4HKHKqNsZeQS+gQOde7M7OEwL3GZ3cJgSuM3u4DAlmKzOTkTdUdrceWV2IiBmbG9JUr8DQKCwE/KQBxVpmvDALBdv7Iq6HHS+Zsh6c6ZmwIL+NFB2DAw+Q5JJpVJTH9I0W2W+WwMyQ6vMJzG0LXF+CnmfqKcPIqmz4xlBCR5vA5VuuU58ZlKqc4UIbui9D94/Lnda8izl6D1M9PjNE18RdVUgtKwAGUZFmRHnD7AX3tlLMtosATOlVwXz4Kw0FRZAenHp5ClRF5RozoRzlq70+CtmwCynzlKikOuWF6UHoKnxmrv0yvPj8tkTT4l2D9x+jMfkyfHv7PBZUw5RdK29TdEuDnlcoSI+SUZb2V4Lb7wxpmqM+b4x5kfGmGeNMf9i9PdbjDHfM8acMMZ8yRh16uDg4PCWwn7E+ISIHrHW3kdE9xPRR4wxDxPRbxHRb1trbyeiXSL65PUbpoODw7ViP7neLBFdtsWEo3+WiB4hon88+vsXiOifE9HvvlFfxvPJbw75vTIVsGAaLKru7skAl5vAzLXgswCxoTnoIu6jo4INloDfG/ngq6HyLEMvOe1lFbHo21FBIQLo/aYyvJYl8t5L8TmFgI4QMteWhU7/BEE4A2V6g0CeUgRFqGy1YNZJVAqsA2ur4/IeBCjdc/+Dot1fPcUBLqt3HhN1Z2HMy3CfhQqA2m3zeGPlOVkE/C6aBUKQTirnLYbgERpI01sJAUA25PsMlTegeEraHGt4Xb3zPe8Rdd958YfjcmuDOeutWn8RcBFGKmdCDGPutMBsq9RUAxbSVKWvqtWHc9V7g9f3fvOz+6MMrhtE9HUieoWI9qwdM/idI6LDV/q+g4PDjce+Nru1trDW3k9ER4jo3UR0134vYIz5lDHmSWPMk0U/u/oXHBwcrgt+KtObtXaPiJ4govcS0bwx5rIsdISIzl/hO49Zax+y1j7k18PXa+Lg4DABXFVnN8asEFFmrd0zxtSI6EM0PJx7goh+mYi+SESfIKIvX60vPwxp9uBQH4w3pVmhucqRSyaV+rwPro2Rx3qXP5B6y/qpM+PyvDInYR85piTW5A/wWUfOGXB1RdObdlH0QMdLlX6J3qK50sWzAH97uVPtcouquKd0TwtnCXg+ECme9BLdbOuSRKMPTT1oNqvavfTjH4/LRx96SNQ1bmfXVw/MYb1Avl+Q/9xG8l4MnKcIs2Qu5+PSyRPj8lyuiDUDfmYGzlIaVWn+OrLG0Yk7GxdE3dvu4Wi2jW3J197pAkHkNpt7fXWk40Put1BZx+IepCGH51dVRBl4ztJX5z0H5ofPpuXLfHyI/djZ14joC2aY4Nwjoj+01n7VGPMcEX3RGPO/EdHTRPS5ffTl4OBwg7Cf0/gfE9EDr/P3kzTU3x0cHP4TwEQ96LwopMbRQ0REdPGs5BHzCpZtPGWW29ll8ShYZM6vqiJCyJDUIJdiaxqzyDzb5O8VysyConuhoo6owGg5MH8lsp0BUWxBpRLyBtxH7EmzXILyOQzfqKMVTEvlqUg0QbABZrjAah47no9OIc1EZ8H88+g/+PC4fPK0fGZ+n0Xa7kWZKrm2dtO4nCxDaudUitkZ3ECcSbOcDxx9fXhOpiXTFVdb3GdPmRFLH+YbJNzFyoJohymtq3X5zA7fwpz133nmaVFHMHdrJa+r9YqMSjOCX1Cl7IohpwHkPjBN2UcFIjeDQHEKzgz7tMoxFeF84x0cpgRuszs4TAkmm8XVM1SOiAwqC7Oiqtdh0UwKL0SXgEDhAIg2kRJhQzjq1qQOSJ0sRV2JHERpozydUHAySHKh6HuRKAKz0xIRDYCYI6/J6S/geiX0r8dRQqCKDXSQDLfF+7TK6oCqga/I324+ysEpc3Ms0v7N00+Kdqgq7ZySlteVKn+vXgX674EUwWmG56pQIngGlhcPVKX1lyW/W60Ewg6VsqsLRBR5h8VlW0rVazBgVeCX/uv/UvYBlozESFUjGHCfTQhyWu9siXZlzP0naowFrKwU1lLWk96AM5BKLFIqYFYd9XHlOBj3ZndwmBa4ze7gMCVwm93BYUowYd74gnqdof0jaMj0v0mbI90KleYYCR190BMDlcJnYY7NcnH/kqhDawemMQoUuUQJNi9feXuhbp6BB12iyA6q82wyGiTS1IRIc20OYz0Mx+irM4EMI+eM4hYHHRI9xrzXePmBLpvIOXjHQ28bl1t7bPbc3pTkEgEQYPQuyEjFyhrrmxmYM/2qIhwx8DxVHXofti6wDly05ZyKVNqZOsiBuQugrp/0RLO3P8iuJD3lnfaDp9nclqkU2dk2j+vAKuQIUDZRYyHKcE/27wFJaALEJ34gTcsRnGlUfLk2E3N57VwDeYWDg8PfD7jN7uAwJZis6c1asiNvIe3kX4JIqzNlJj02V1kICmkoQoYcTF6xJ3/H0PTkg1lLB8IgR3u1KtWJGIJpen0WJTPFQV6B8WdWmnhiMOOUFdl/CWJmgamb1BiRz16nMcqA1AAztwaKNSzIue7QUZmiqg5Zc7c2To3Lg74MsjAWPLq0+ByzmBzOcdBJGCgyD1A7skKK1lWfx3HuHKf6qkUyiKXbYxVCc/3XYIwd8E575/vfK9qtgZfcCy/9SNT1O6ySDDotUeeDKbVfwvpQqkAAprJEkbMsgsdeBltyu70t2gVNyDmgTMvRSPXVWYkR7s3u4DAlcJvdwWFK4Da7g8OUYKI6uykLCvtD/ccq08FMg/WRrkrJi0QOAUQPaRKASsR6UUWZzQzY71CvtSr3GOZY862cnt0O66ytLuuXmlSyCkSBsbqXMmQ9VAfVIcd8/gaElnjO4CnTWwFuoDnojRlJHa8O6YDveuBeUbcD97Z+id1gU+Xq6od8RhLMST06XAE3YfB/DpUJMIEzjFiRlnQvsPl0FpgUk3kV7Sj0Vz1vfPHDx5hQ49GPPSpavXqJI/rabXk2AZYxunjqnKi7tc5j6ft8L6FyYw7gLKg00uxcqfP39s7zfOscfymc43hKN18cpY4OvCuHvbk3u4PDlMBtdgeHKcFExfiADC2NxOS9jhQJl+bZ+23jvOQAq9VYFGvl7GFU0cQT8LmhPPQKNBshsYWn+gCRPFIictxn8T9HbjllXqvOsAddoUyAcYoqhBRHUTALgFvOviYPL3xW4hx68xUl31uiPAUry5wauFvKObhwkT3leutMUBHmSm9q8L2tHpXplv0qz2MQQEqtnnzuGKXm5XI5nnzu5XH5yBwTYOSZembwnLTpKQjZvPmRj350XO6oiLLtPb7PTHGyd8G7M+lK01tc4Xm0PTbHeko9jMC89sr5U6LOYvgmqJtak8vAG1CrQ3ExVBdLlbIM4d7sDg5TArfZHRymBJPloCstVftDMbOpgjtKENW9vsqwCU23QhbZjgfSAy0BiuFI8dPlIN6FIFqnpaaShuyj6tQ37bOInANfWqBUAQNeYrGiPc5AFPa1NxlIoAmI+4Gmi4b5SAaK0w3UixxOuitKFTh8263j8okzZ0Td3iWm+e7DyXyRqqChRR5wdVHl9YxYBo27LLoj1yARUQAROvGOFK0XwXIRA/HE3JFV0a4HzyJJpJpw8NDN43IIa2xzT1JC77TYW63oydP4Sxt8Ql6PpGrnw6MPQAS/+6bbRbvWLve5sytVgfkDLOIHQo0UzSiCtWM8xXt4OUDnNSofw73ZHRymBG6zOzhMCdxmd3CYEkxUZ7e2pDwZ6ld1pVq0Bqx3zSzNi7rONus7psbtsrocfgSmt4on60rQj1FNz1T0UAgRcXki+dSLnPVGH/RhHWjUhXS9SpOlGMgRF3JZa0O+tgWTlI7MK0G5tyrazIcoL6/kM43lxqJo9/ZjrFO++Nyzom4zAz09Y90wK6W+WmmyiVGfP+RALJJ0uL8olJ52EUxetiX16BlgHCmBH+Tg7JJot5HyfGelJBK55x33jMv4XHY6MvIsS3m8/b587q1LPK7DkaRDLfo8P7evciLj0+uSRz+J+Rn21TnOguV5DeDZRkatTSA3qeRyvv3RXvDeDMLJUdrmp40xXx19vsUY8z1jzAljzJeMMXpdOzg4vIXw04jxv05Ez8Pn3yKi37bW3k5Eu0T0yTdzYA4ODm8u9iXGG2OOENF/TkT/OxH9j2bopvQIEf3jUZMvENE/J6LfvUpH5EWj35eeJCqwwK+1tLIs6nZAjLJIdlCTpreKYdGmpwJtanXwqINr5UpEDgPgS1NpqGzMIlsE4jIGvhAR1SH1D/KFExFlcL1cZWf1wDOuBPNgqURk7KPQ/PiQ5gqr3nbn20W7MyeYe72lMpNiqqwEPB1Lpa+gZ2ORSPE5hqChAMxthXq9RAXPnacCP9DbsBayeSruSxNdVONO335M3metzmskyfhZdNrS/GVAXcnV2pwBlaqmbuCOt/P1Wn3+3hZw9xERZX14tso8lsSwDoBgw1PmNayjmhSkK42h6mu8K2/p/b7Z/zUR/TPiDGRLRLRn7dhP9BwRHX69Lzo4OLw1cNXNboz5GBFtWGuf+lkuYIz5lDHmSWPMk2k3ufoXHBwcrgv2I8a/j4j+oTHmo0RUJaJZIvodIpo3xgSjt/sRIjr/el+21j5GRI8REc3fvHBl9x4HB4friv3kZ/8sEX2WiMgY8wEi+p+stf/EGPPviOiXieiLRPQJIvry1foyJZGXDPUfW0gdrwb84TMVaVrxwUU2AT23SKSkgOafQhEhFFCXwPcSlfOrBiSHcV+OEd1FUVOuqAg7gggzLTqVoJf3FbFF1QChoHD3Vb+RBog4VJrjEsgb1g4zkSTq10REWxsb43Icy3nMIa00pjKuzMqzCVPC9wZyjEXK46iBuW2g+OXXZg6My34ql+Og4DnogY69oIhJlhZXxuVb7rhN9gEpomMg30hjaV4zEC2I0WtERHV42Lffcauoq87ys3/+xDPjctRoiHYb6xzJWah04vEged06T9nRSiT6UFF1B2++i4iI/OgFuhKuxanm0zQ8rDtBQx3+c9fQl4ODw3XGT+VUY639BhF9Y1Q+SUTvfvOH5ODgcD0w2fRPeUm9zaHoOjMjL23ALJK1FbHFEov1mxeYAyxX4rMF01ChzBtRE81hEBmmCTAgwsyPpGkvqjGvWgxc4rVAJZmGLovXRL2B2U9x11kQ05D8wL6GCxzJK+R9ouh38803jct7LSk+t7s8/iCUz2Jrk01xOXg2hiqyLQevs7qabyQBMT0W6YsdKT5HVUgdXcr5MJAGLIa0S5ky0R06xPc56KmUyiH332qxKhAqTj5MUZUqM+LqCqsJx47LaLYnvv3NcbkAko7F2gHRrt/h9W2UQI2Riug5WarUzinc99vuv0/UFYuHhgXFfYdwvvEODlMCt9kdHKYEExXjsySjcyeGp5J3vUuKOTMpi3Dbisp3doHF+AsX+FSznUtxrg6BE1V1gO1XIa0OcFB7PdkwBKm7pbKzvu/nmcPsz574xricxnK8EYiIqZKqSvDUMlZWosdbCfeWKIINAoKNPJHWhJVZ9m2ycLqdG3nynza5zkul+Nw5z95fQQ3aqXRYIYjqhTrdrlpWsfbOslpQUU5hkX9ldSWEQBAkFWmotFkFtLMqw2tZB0sOBDZFpbyWAR+QRijVsnsf4qOp555/WdRtbbN6tHSEefiKvkrPBM/9Nfx0xIuuxOAfX57o3/aeD/N3lqXFauul54bXjTUNO8O92R0cpgRuszs4TAncZndwmBJMVmdPU7pwbmg6u/XBFVGXgueXp/jJQ2LdOYJ0yK2B1E9Wm2waC1XUGzJM+GCeSBUHOfKOJ4o//E8fZyfBBx98eFx+6tm/Fe38GLjbM6nLZinrZLWKNB1idJUFz75S6ewGovEK5QG4sggkFeBp1vVlH4EBXvptaeoswHOwOs8EFanyWIzQ7OdJs9xgj/swCZukakovj2H82sA4AE82C/d8+NBB0W5nmwkyFxSxxXaLzwtS8OoLld7swTp4590yci4K+N6ee0nq7D5soUPzfA51fmNdtAur7EVYFnIeMxhKGfIavu/hD4p2s6t838+98F1RV+2uj/p2OruDw9TDbXYHhynBRMV4Kg35/aE41l2X4m0DsoBWSIo5aZdFsWaVRfC9gRRhB8g/pkgpMmGmA/NGKYMS5iEN1blzMmNn0mEPrFOnT43LywdlKH8GAS6+IhPIgJDBqICOwoCnWYyE5CrFE6b48WX/yFfXh4CcgSLKaAA5xmBXeteJdFMQQNTrK5MoBOtoM+LKKqtpmz2eR1vKcaSgbgW+ykAK47jp2E3QTs6HB8+wR7J/wdsP/cWKb/+WQ4fG5VtvlcEuf/nX3+IPyrsugC10eIbXzumTp0Q7C8FcpQpeimG6jz/4znH54JE10e6b3/7zcXl2UZGu9IbryhQu/ZODw9TDbXYHhymB2+wODlOCiersxlryk6GCsv7qlqg7/gDrZFVP5UBLmMgvBH07VTltUV2pKdNKkmBuNjDDhSqyCFxkI6Oi2cBsdu4066E33X+nbAf5y1JlHkSyy0CdF2AdmgTzioqSAiPV/Jzkg7egs2dwz1FD9tEH3vSd3W1RV6mBmQjMfqUi0chwrjRDPnCc3/3Ag+PymQ3Jp96B84ee0qPxEd59H/C/K8LJANJDd9W5QgrnFniqEKiIsiM3HxuXX3jlVVF36uTJcTlSBsKKjy7DfB7T25PnIJhKW51M0O33sKnv3vc+NC5/48++KtrZEohBU+kybHujySq1AZPh3uwODlMCt9kdHKYEk03/RJZyOxR12i0pivVj9uLyK9KsUAHBxwNOsWoizSydFov7zZpMM1SDwP8ukC5EdSkOoXed58m6IGRRFVM2b69fEu0WD7JnnA5YyyFdU1ulIKrNsLcaAde6DXTUGxBsWOUJhl5tOaguKmHPxi6LhIkydc4d4HHsFqj+yGt1gdii3NkQddvPM//o+jJ7li3cdki0a6MpqymjvJaAN29mmcfUTaWoDrdJnpVmrRzSaftgfrz92HHR7vxFHv+zz8h0WDZV8w+YgWfW63G0oKciJg3M1cqt0qT28Ec4mu3igO+trMn1XYIamav79C+rporMBOHe7A4OUwK32R0cpgQTFuOJihFldK6C7DsbLILXV6QIDk5zVMDptqfIK3ogAhnFT5eACOSBOFptyna7wFO2syvTAB2ALJ3nznOgw9Y5KcbX5lhMK5WYXcCYS0UV7Hl8owXBffrSOy208NhSeaKfe0B3DZ5mNpbtOsjHpvjjfEhnVfbY09F/jVci31ukeOGq4FGXb7G6sp7IoJtghQNXqvMzou6mW28el3d7bDEwyoKSA+uHp1JxLRt+vkvAQzjXmBPtTm2dGpd3tqSlSMT7KAPKYp1VjwS4Ez2SDRcW2Lvu5x95VNS1Ul5nux2+z1iRojQi4PVL1LMYXc9q2nGAe7M7OEwJ3GZ3cJgSuM3u4DAlmKwHHVnyR5FdhSI7uLjJOuSBBWmCISAUjErWSUKlnrT3WGeya9LEU8DvWg5eVdWm1N16cHZwYUPq4m+78/5x+aWT7AkWzUoTnQEvpiBQUWmQVrpQZw6ViM8qdrs8H0alCZ4F/nqbKi9C8N7zZ1lHbW1LLznkKveUVxiSQIYQpaeOGKgM+b6jUD7PsuQzB1SxQ+U/FkGqqY6KWPMrwKEOzy/OpaedB/Om+CxpGeYK0y2fPX1GtNtaZwIMHRHXDFjvzxWhSQTkl50+P7PavFxX7/vwx8blRLnQXYJ1dvqFn4zLM5kcR4BrWHlfxiP+fXtlB7p952c/RUQdGqY/yK21DxljFonoS0R0jIhOEdGvWGt3r9SHg4PDjcVPI8b/grX2fmvtZefdzxDR49ba40T0+Oizg4PDWxTXIsZ/nIg+MCp/gYY54D59tS95IzE2iOSlU/CM292TJq/6EotRKMqYTIpUBZBGZJkUc0IQewKPvY+SvgpYANKIfl9lN62DKcuwyNmYa4p2mykLOMdvfoeoS7dZ1Eu3NkVdiR5qyE9h5VxVIC1SobLhYjCQB+rE1q4UugyaAJUnYhSBCbAPakFFmkQtzKPiriDrcZ8GPf5KqbrUQFSvrsyLuh5wtQXC2iifrQcZgINIqhMpeDoONliVGXTls30V8hGUar4NqH2+8lCrNvl6p4Gz/rZ33SvaZYbrttflmjsN1+4Dd918JN/FNZiErsoAHDeG4yhfkyqMsd83uyWivzDGPGWM+dTob6vW2ouj8joRre6zLwcHhxuA/b7Z32+tPW+MOUBEXzfGiCTQ1lprzOs75Y5+HD5FROSFb3B64ODgcF2xrze7tfb86P8NIvoTGqZqvmSMWSMiGv2/cYXvPmatfcha+5DRgbwODg4Tw1Xf7MaYBhF51trOqPyLRPQviegrRPQJIvrN0f9fvnIvQ4S1Gh14x11ERLTTky6J/QGbzc6flvrl7QeZL7sSsM4beSqfFriVxirqqCjYKOMT6LyZ/L2LKqx/+3AtIiL0fJ1ZZPPg7Iw0FeYluzkeXpT8+LuQvngjkzp7GnMd8iTWAqWHIqGlcnXFJ5pgGmxNRAjurVbVIfFjCe1yZaLLwX220ZTzGM6BORLuGc1pREQ+tJs5KDnf4wCujXp6JA8I0NwWqXvZXmd9uIBIyzSV87a7y8+6rvR+TBFt1QurAGkV3XtXD8rnfgZMfduXpM5+7hSTYyzN8fmUr6IME8gX1+or8+DY7fvK0vN+xPhVIvqTUfKEgIj+X2vtnxljfkBEf2iM+SQRnSaiX9lHXw4ODjcIV93s1tqTRHTf6/x9m4gefe03HBwc3oqYqAddnqe0tTUUq/yG8rgC15+tS5LYIu3xMCsli31lIcWhKqQUTmIp5oTA42ZjlpFjxUuAqZL9QEbElWDimVlm0b3oSw78AKKw6j1pInn1NHve2YFKF+1Bnzl7VVUqcq4s9J+pVEI5mNs2N9nU5CtOdg/MOEUp5wpTJ1vgrM8VEwfy18dG1nnwvcSCGc5IMbu+usx9qFRWHnobonSqUkfXIvBiOy057soLrBLW6+xRuL0rVTTMM2CUalTCfTbmpHlwfoWJOaqLs+Py+p5URXeBm//Cq6dE3XKFxxXCXHnKntkDFcVTpCtXjnVjON94B4cpgdvsDg5TArfZHRymBJONeitKikZsHmEodR80lCXKIH/yZeZoP3IbmMYURzZqfLFiwonA1RN13kTlQIsqzJbi16TOVEJEmQWVqexJvbkK6ZAjlRI6yPnzblu6BQ+Ahada5fvU+hjy3se5NDFmcPZRwn2GoeTAx4+ZOleo1vmsooA59tR8I6+7VXV4BgO3TH5dnoPkNT6PKJXeX4A7dAjPr6/cZVub7OKRXZSRitUeuD+DKauleN2RDz5U5jtMLXf81mOiLoTxXwAz33ZL9t/Z4c9FIs8m5mf4YeAaywu5NjFfn5mRLtrjfAHaFAtwb3YHhymB2+wODlOCyaZsJkPliLwgV9E5HnhLFbkUo84Akd+yB6mdVR8JCPJxolIxQ1sPItaQ7IGIyAuBKKMpxS0DHntLawvj8rryiKqFPK15V5q1ypDFrzST5pksYxNeZYnVHC3e5gn36RVS5dnd5rGEa5waqgxUFGCKEXzyNz8H1SMAYgirSDQMiKOBWkoYiVaA2L24Kj3L8gp/L1Piba/Das78PLcr1SuqDWatWib7yMDtMe3zfaUDJaqn3K5QBJ/H3waecYdkuq12BwlKWYxPOvK599fR81NGD6InYg5iuFWRmxai7yrKu660w/t2hJMODg5uszs4TAsmzEFHdFmASRRhAgGXV31GilEHVphPrtthkb4ayhPJfo9Fp1LzmINoNoDT8sJK77fSB+7viiIIAKKLxjx7u/nKo8uCGJwMZP8DCGIJlRdUZ8Bi61KN1YQsl+PwgLCivSV52OM2i3prq+zRlQXy5B9Vklx516GFAt8GqRKRDahG6mmSDfib/QZ4QB5dFu3ykNsNOsqCAiJpDrxw7a7kU/cghVShTqOND2m/WjxXg0J6JR48cuu4/M73vlPUNUL26MwLOd/bmyC6g2dmd1daSfa2eMwrKuDHA89EdDDMVU6AClgyskI+i3SUDqp0p/EODg5uszs4TAncZndwmBJMVGf3DFEjGOqHvVjqNEGD9cv2noxI2igvjsspEAUeXZO0d33wWvIr8tYy0OtsiWY+nY4X8pe9hgudrx2D6Wp2UXoDxutsUstTqc3GwMOudf0EOMlT0NO16c1CZN6lM4pgg9gbywOyRf2rnsN9x5l8FlUg1kRvr1KZgnyYHk8Rlmcl3/fSTUw+EstbpiLj++y0pCmy7vMzxPMC21MRjWC66qgzkhkwc8WgU7/n535RtLvzHtbTT736fVFnC55jL5bekv0+6/O25PFunJeRm0HJ44h8qVdbYHRDU2pqpV5egTUdqByCNEor7b1B+Jt7szs4TAncZndwmBJM3PR2WUgplddWAWQKWSpFsaLPsl84z+aHSk2ROkBQSHtPmnGKQ2zyKUHsqwRSriyBk05ZN8hHURX44moVyUFXhmye6asUxUWfTTBhY0HURXUW4frAHxeogXjgCdbeliJ4BHx1g12+dhHI+Y7BzGdVeuFCcOGx2Ko9G0PwFKyWUl0BunlaXmWChzRRwT9tno+qCkDxTzp9twAACxRJREFUIIVUCipEkctrpaBq6Gc2ALn2XT/34XE5UGbb73zzj8flQwfkukJet61tlWcAgo2oB+bGi9I8WJuBdNS+CigCz0RU0bQZMQNzaaC0z9lkuI49Ld4D3JvdwWFK4Da7g8OUwG12B4cpwcSj3uxlrV3l/MLUw55KvJuAflltrI3Ll7pSf2ossg68u3NR1MUDMHlBhJ1m2UbCyddEHQHXeAT5oit1qeP1QT9u96TOnoLZyKtJnd1v8nlECa6iyCdPRJRCTjGMhBqOi/X+GFyLK0syhXAGLrGlcstEsxlGsxWlPB8oIZqtNHKMdUhZ7MGYCmW6Slt8PiNpLYhKIKAUkWFKt48TUGBVZN6d97yb+yN2mf7bJ74m2j147+Fx2VfOv90uEJTG8jwJW+6dY9NhqZ6ZneXnmSnizhDeuQnMT2VGrqsIE94p1+XLd2Zc1JuDg4Pb7A4OU4LJivHGkPGGlwwTxZ02gBRBKsdOmkKaoRn2Vju9I9PLzc+wWFxpyMg5zDsZgNkvVGIwireBJ8dRZqhqANdbLj26qrNszhu0pNg6AM/BqkpfZYFbzgIfHZaJZNrqyFeEEnA/PRCRo1yamrIB3GcuxcV2C9SEkufA8xRBhcfXShWRyPIiXy9PWQ0bKN69MAN1JZFzhZdDijttAgTHQ7rtyHFRVzFs8nr8a5yh7D0P3CLaZTGrhEEgVZ52B/jjfL1uef43z0IfpVx/6NDpK9Mbeilai6qi7CMAyd2PZR+VkUp1zR50xph5Y8y/N8a8YIx53hjzXmPMojHm68aYl0f/L1y9JwcHhxuF/Yrxv0NEf2atvYuGqaCeJ6LPENHj1trjRPT46LODg8NbFPvJ4jpHRD9HRP8tEZG1NiWi1BjzcSL6wKjZF4joG0T06av1dzmlTx7LE8+gxoECiSdFFCSeqBCLlZVcitkGxN3AU15hcAIaAlmDp2iJCXm+VPbUEkgjjAmhLO/Fr3Jdb0uRY4Ao1mgoemcQ4QycMBcDdQpewLWVl1UOATr9i3yx+bvkfRoQz5sVKeKfP7s+LvsBiJIqMMMDNUdJ8VSNgEq6D4QginYbVbSkLy0XCytM8lBCYFCey3uebbJQec/bJfHEl/+fL43Ldx9jEpRArfwU8kt129L7LSv42oXi8uu34JS9z33UjLxAVOU6bQFKwe0vhIFZtT2DhNdjvC4tUYtLw0AyY3XvjP282W8hok0i+rfGmKeNMf9mlLp51Vp72b61TsNsrw4ODm9R7GezB0T0IBH9rrX2ASLqkRLZ7fBU4XWPBowxnzLGPGmMeTJXdmsHB4fJYT+b/RwRnbPWfm/0+d/TcPNfMsasERGN/t94vS9bax+z1j5krX0oCJ2lz8HhRmE/+dnXjTFnjTF3WmtfpGFO9udG/z5BRL85+v/Lb9ANERGVRNSjoY42KKRuMZuw/tdQJq96k01ZJ3Y4vU+m9KcsZl2rofTQQYvbhlXgILeKzBF+/wL/yibAvIA+QinUeBF/L+nLMZYZmOxKqb+imatugHRBRaV1wWzpRfIRrsyzafLEyVfH5TBdE+2qddaH+5tyDmyfx1WCt6G+zwSEuYVIRg8WkDI778NZR1/+4O8Bn3p9QfKpoyDYBQ75+uIR0e6RD3xsXP6Lz/+BqMNjkbll9tHr5ZJcwoNzop6KuiwrXNf05DnL+bPsqenBmi5CaVYN4AzDqrRObfAerUIqqJoiN4nXeVxZS57jxM3hOijfQGffr539fyCi3zfGRER0koj+OxpKBX9ojPkkEZ0mol/ZZ18ODg43APva7NbaHxLRQ69T9eibOxwHB4frhcl60FlLxSgAxiovqASDNlRG0PoCBP7Ps3gexNIby7YhiCBSIiFkdfW9WShL81oCsqNHysMNueghGMOPpLiPkpRRIrgBF6e6It9Ie6yG3Hv8vnH523/9PdEOg2T8qrx2BHz2UY0f786GNCc9/J5/MC4/eUH2b8F8hy5ZOsgiDMCEqbzCMC1vPkDPQ+UVhsNX2XsTnG+f18AjP/9Lot2ZF1ld2d2TPHb33MepmwYe5BUIlGcjBPmUTRmSUwK33NYFqfJkoKYhl1zpy7UDVWRV4JGB+65FvCbqhRTjXznP2YwDZX6sj7j3Sm1KBrgTMweHKYHb7A4OUwK32R0cpgSTJZw0hqIRF7inCAgOrLDL4066I+r6GAnkgdmiUNzzqK8UyvQBkW4lEGdkigTAB55xHX1nLet56KZq1bWQiNFTRI81cAvWrq69DT632Jvd5j7U2UEBCuDiYZkCOUWOeTCbdRQXfwJpjuOWMkOB7yvqmpoDf8ZnnbKmOPb7kLetiMHsqcylaF4qVFRdnPM4Hv4F5nlvt6Vp7NLpk+Py2k0yj5o/x30MYL1kau79Gp8FKX4NmquyOfPi6Rfk9xLMd8dzX1r5zCJYS0kmLxACYWkFzM52R0ZTJpDHTwUqUm8UeVlap7M7OEw93GZ3cJgSGPsGKV7f9IsZs0lDB5xlItqa2IVfH2+FMRC5cWi4cUj8tOO42Vq78noVE93s44sa86S19vWcdKZqDG4cbhyTHIcT4x0cpgRuszs4TAlu1GZ/7AZdF/FWGAORG4eGG4fEmzaOG6KzOzg4TB5OjHdwmBJMdLMbYz5ijHnRGHPCGDMxNlpjzOeNMRvGmGfgbxOnwjbGHDXGPGGMec4Y86wx5tdvxFiMMVVjzPeNMT8ajeNfjP5+izHme6Pn86URf8F1hzHGH/EbfvVGjcMYc8oY8xNjzA+NMU+O/nYj1sh1o22f2GY3wzi+/5OIfomI7iaiXzXG3D2hy/8eEX1E/e1GUGHnRPQb1tq7iehhIvq10RxMeiwJET1irb2PiO4noo8YYx4mot8iot+21t5ORLtE9MnrPI7L+HUa0pNfxo0axy9Ya+8HU9eNWCPXj7bdWjuRf0T0XiL6c/j8WSL67ASvf4yInoHPLxLR2qi8RkQvTmosMIYvE9GHbuRYaJhP8e+I6D00dN4IXu95XcfrHxkt4EeI6Ks0ZFq+EeM4RUTL6m8TfS5ENEdEr9LoLO3NHsckxfjDRHQWPp8b/e1G4YZSYRtjjhHRA0T0vRsxlpHo/EMaEoV+nYheIaI9a8fk8JN6Pv+aiP4Z0ZjlY+kGjcMS0V8YY54yxnxq9LdJP5frStvuDujojamwrweMMU0i+iMi+qfWWhFyNqmxWGsLa+39NHyzvpuI7rre19QwxnyMiDastU9N+tqvg/dbax+koZr5a8aYn8PKCT2Xa6JtvxomudnPE9FR+Hxk9LcbhX1RYb/ZMMNUMn9ERL9vrf3jGzkWIiJr7R4RPUFDcXnemHEqk0k8n/cR0T80xpwioi/SUJT/nRswDrLWnh/9v0FEf0LDH8BJP5drom2/Gia52X9ARMdHJ60REf0jIvrKBK+v8RUaUmAT7ZMK+1phjDFE9Dkiet5a+69u1FiMMSvGmPlRuUbDc4Pnabjpf3lS47DWftZae8Rae4yG6+GvrLX/ZNLjMMY0jBmmex2Jzb9IRM/QhJ+LtXadiM4aY+4c/ekybfubM47rffChDho+SkQv0VA//F8meN0/IKKLRJTR8NfzkzTUDR8nopeJ6C+JaHEC43g/DUWwHxPRD0f/PjrpsRDRvUT09GgczxDR/zr6+61E9H0iOkFE/46IKhN8Rh8goq/eiHGMrvej0b9nL6/NG7RG7ieiJ0fP5v8jooU3axzOg87BYUrgDugcHKYEbrM7OEwJ3GZ3cJgSuM3u4DAlcJvdwWFK4Da7g8OUwG12B4cpgdvsDg5Tgv8fKQZCe7vKL0cAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Healthy\n",
            "85.24495363235474\n",
            "Leaf rust\n",
            "0.07042534416541457\n",
            "Powdery mildew\n",
            "0.0011494312275317498\n",
            "Seedlings\n",
            "8.796852827072144\n",
            "Septoria\n",
            "0.004091470327693969\n",
            "Stem rust\n",
            "0.0034832977689802647\n",
            "Yellow Rust\n",
            "5.879047513008118\n",
            "PREDICTION: HEALTHY\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "GP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}